# MCP Server Inventory & Recommendations

## Current State
✅ **sequential-thinking** - Installed
❌ All other categories: **missing**

---

## Recommended MCP Servers by Category

### 1. **Filesystem & Search** (P0 - Install First)

#### `@modelcontextprotocol/server-filesystem`
**What**: Enhanced file operations (watch, recursive search, glob, tree view)
**Why**: Claude's built-in Read/Glob is good, but this adds:
- Recursive directory trees (faster repo exploration)
- File watchers (detect external changes)
- Atomic multi-file operations

**When to use**:
- Large repos (>500 files) where you need fast tree views
- Monorepos where you want to scope searches to subdirectories
- When you need to watch build outputs or autogenerated files

**When NOT to use**:
- Small projects (<100 files) - built-in tools are fine
- If you're hitting rate limits (this can be chatty)

**Install**:
```bash
npm install -g @modelcontextprotocol/server-filesystem
```

**Config** (add to VS Code MCP settings):
```json
{
  "mcpServers": {
    "filesystem": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-filesystem", "/path/to/your/workspace"],
      "env": {}
    }
  }
}
```

---

### 2. **Git & Version Control** (P0)

#### `@modelcontextprotocol/server-git`
**What**: Deep git operations (blame, log with patches, branch diffs, commit graphs)
**Why**: Beyond basic `git status/diff`, this gives Claude:
- Blame annotations (who wrote this line, when, why)
- Commit ancestry (find when a bug was introduced)
- Branch comparison (what changed between feature and main)

**When to use**:
- Bug archaeology ("when did this break?")
- Code review (understanding change history)
- Refactoring (finding all commits that touched a module)

**When NOT to use**:
- Fresh repos with <10 commits
- When you just need current diff (use built-in git commands)

**Install**:
```bash
npm install -g @modelcontextprotocol/server-git
```

**Config**:
```json
{
  "mcpServers": {
    "git": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-git"],
      "env": {}
    }
  }
}
```

---

### 3. **Testing & CI** (P1)

#### `mcp-server-playwright` (if you use Playwright)
**What**: Run Playwright tests, get results, capture screenshots on failure
**Why**: Claude can verify fixes by running E2E tests and seeing the actual browser output

**Alternative (generic test runner)**: Build a simple MCP wrapper around your test command:

**DIY Blueprint** (`mcp-test-runner.js`):
```javascript
#!/usr/bin/env node
import { Server } from "@modelcontextprotocol/sdk/server/index.js";
import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";
import { exec } from "child_process";
import { promisify } from "util";

const execAsync = promisify(exec);

const server = new Server({
  name: "test-runner",
  version: "1.0.0"
}, {
  capabilities: {
    tools: {}
  }
});

server.setRequestHandler("tools/list", async () => ({
  tools: [
    {
      name: "run_tests",
      description: "Run test suite (or subset) and return results",
      inputSchema: {
        type: "object",
        properties: {
          pattern: { type: "string", description: "Test file pattern (e.g., '**/*.test.ts')" },
          bail: { type: "boolean", description: "Stop on first failure" }
        }
      }
    }
  ]
}));

server.setRequestHandler("tools/call", async (request) => {
  if (request.params.name === "run_tests") {
    const { pattern = "", bail = false } = request.params.arguments || {};
    const cmd = `npm test -- ${pattern} ${bail ? "--bail" : ""}`;

    try {
      const { stdout, stderr } = await execAsync(cmd, { cwd: process.cwd() });
      return {
        content: [
          { type: "text", text: `✅ Tests passed\n\n${stdout}` }
        ]
      };
    } catch (error) {
      return {
        content: [
          { type: "text", text: `❌ Tests failed\n\n${error.stdout}\n${error.stderr}` }
        ],
        isError: false // Don't treat test failures as MCP errors
      };
    }
  }
});

const transport = new StdioServerTransport();
server.connect(transport);
```

**Config**:
```json
{
  "mcpServers": {
    "test-runner": {
      "command": "node",
      "args": ["/path/to/mcp-test-runner.js"],
      "env": {}
    }
  }
}
```

**When to use**: After every code change (Claude can auto-verify fixes)
**When NOT to use**: If tests take >2 minutes (too slow for interactive loop)

---

### 4. **CI/CD Status** (P1)

#### `@modelcontextprotocol/server-github` (if using GitHub Actions)
**What**: Check CI status, download artifacts, list workflow runs
**Why**: Claude can see if the last push broke CI and fetch logs

**Alternative (GitLab/Jenkins)**: Build a simple REST wrapper:

**DIY Blueprint** (`mcp-ci-status.js`):
```javascript
// Similar structure to test-runner above, but calls:
// - GitHub API: https://api.github.com/repos/{owner}/{repo}/actions/runs
// - GitLab API: https://gitlab.com/api/v4/projects/{id}/pipelines
// Returns: status (success/failed/running), logs URL, failure step
```

**When to use**:
- Before starting new work (check if main is green)
- After pushing (verify CI passed before merging)

**When NOT to use**: If CI takes >10 minutes (just check manually)

---

### 5. **Issue Tracking** (P2)

#### `@modelcontextprotocol/server-github` (issues), Jira MCP, Linear MCP
**What**: Fetch issue details, link commits to tickets, update status
**Why**: Claude can read the full context of a bug report without you copy-pasting

**When to use**: When tackling issues from a tracker (Claude fetches requirements automatically)
**When NOT to use**: For exploratory work with no linked issue

**Install** (GitHub example):
```bash
npm install -g @modelcontextprotocol/server-github
```

**Config**:
```json
{
  "mcpServers": {
    "github": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-github"],
      "env": {
        "GITHUB_TOKEN": "your_token_here"
      }
    }
  }
}
```

---

### 6. **Code Intelligence** (P2)

#### `mcp-server-treesitter` or custom AST tool
**What**: Parse code into ASTs, find all function definitions, call graphs
**Why**: Better than grep for "find all places this function is called"

**DIY Blueprint**:
- Use `tree-sitter-cli` to generate AST JSON
- Wrap in MCP tool that answers: "list all imports of X", "find all classes implementing Y"

**When to use**: Large refactors (renaming, moving modules)
**When NOT to use**: Small repos where grep is fast enough

---

### 7. **Secrets & Config** (P2)

#### `mcp-server-1password` or `mcp-server-bitwarden`
**What**: Securely fetch API keys, DB credentials from vault
**Why**: Claude can run integration tests without you pasting secrets in chat

**When to use**: Testing APIs that need auth tokens
**When NOT to use**: For production secrets (keep those out of dev workflows)

**Security note**: Secrets fetched via MCP are visible in Claude's context → only use for dev/test credentials.

---

### 8. **Local Tools (Lint/Format)** (P1 - via hooks, not MCP)

**Recommendation**: Don't use MCP for this—use **PostToolUse hooks** instead (see Section 6).
**Why**: Hooks run automatically after every edit; MCP requires explicit calls.

---

### 9. **Data Viz & Reporting** (P2)

#### `mcp-server-playwright` (screenshots), `mcp-server-puppeteer`
**What**: Generate charts, screenshot diffs, visual regression tests
**Why**: Claude can verify UI changes by comparing before/after screenshots

**When to use**: Frontend work, visual QA
**When NOT to use**: Backend/API projects

---

### 10. **Embeddings & Code Search** (P2 - Advanced)

#### `mcp-server-faiss` or vector DB
**What**: Semantic code search ("find files that handle authentication")
**Why**: Better than grep for conceptual queries

**Trade-off**: Requires embedding model + index build (10–30 min setup, 5 min/week refresh)
**When to use**: Repos >10K files where you frequently ask "where is X implemented?"
**When NOT to use**: Repos <1K files (grep is faster)

---

## Sequential-Thinking MCP: Positioning & Usage

### What It Does
Extended reasoning for complex, ambiguous, or multi-constraint problems.

### When to Call It
- **Architecture decisions**: "Should we use microservices or monolith for this project?"
- **Debugging gnarly issues**: "This fails only in prod, on Tuesdays, for users with 2FA enabled"
- **Requirement analysis**: "The client wants 'fast search'—what does that actually mean here?"
- **Trade-off evaluation**: "GraphQL vs REST for our mobile app"

### When NOT to Call It
- Simple bugs ("this function returns undefined")
- Straightforward features ("add a button that calls saveUser()")
- Style questions ("tabs or spaces?")

### How to Chain with Other Tools
**Workflow**:
1. **Sequential-thinking**: "Analyze the root cause of this performance issue" → produces hypothesis tree
2. **Filesystem MCP**: Fetch the files mentioned in the hypothesis
3. **Test-runner MCP**: Run profiling tests to confirm bottleneck
4. **Git MCP**: Find when the slow code was introduced
5. **Claude edits**: Apply the fix

### Sample Call

**Prompt**:
```
Use sequential thinking to plan a migration from REST to GraphQL for our API.
Context:
- 50 REST endpoints
- 3 mobile clients (iOS, Android, React Native)
- Need backwards compatibility for 6 months
- Team has no GraphQL experience

Output a migration plan with:
1. Phases (what to migrate when)
2. Risks + mitigations
3. Training needs
4. Rollback strategy
```

**Expected Output** (from sequential-thinking MCP):
```
<thinking>
- Constraint: Backwards compat for 6 months → need dual-stack (REST + GraphQL)
- Risk: Team learning curve → start with read-only queries, defer mutations
- Migration sequence: High-traffic endpoints last (reduce blast radius)
...
</thinking>

Plan:
Phase 1 (Month 1): GraphQL server setup, schema for 10 read-only endpoints
Phase 2 (Month 2): Mobile client updates (React Native first, lower risk)
...
```

### Prompt Scaffolds

#### For debugging:
```
@sequential-thinking analyze this error:
[paste error + repro steps]

Produce:
1. Hypothesis tree (most likely → least likely causes)
2. For each hypothesis: how to test it
3. Recommended investigation order
```

#### For architecture:
```
@sequential-thinking compare approaches for [problem]:

Option A: [description]
Option B: [description]

Constraints:
- [performance, cost, team skill, time to ship]

Output: Decision matrix + recommendation
```

#### For refactoring:
```
@sequential-thinking plan refactor of [module]:

Current state: [describe code]
Goal: [what we want]
Constraints: [can't break API, must ship in 2 weeks, low test coverage]

Output:
1. Step-by-step plan (what to change when)
2. Risk assessment for each step
3. Testing strategy
4. Rollback points
```

---

## Recommended Install Order

1. **Week 1**: `server-filesystem` + `server-git` (foundational)
2. **Week 2**: Test runner (custom MCP or Playwright wrapper)
3. **Week 3**: CI status (GitHub Actions or custom)
4. **Week 4**: Issue tracker (if you use one heavily)
5. **Later**: Code intelligence, secrets, embeddings (only if you hit pain points)

---

## MCP Config Location (VS Code)

Add servers to:
- **Windows**: `%APPDATA%\Code\User\globalStorage\anthropic-ai.claude-code\mcp-settings.json`
- **Mac/Linux**: `~/.config/Code/User/globalStorage/anthropic-ai.claude-code/mcp-settings.json`

Or use VS Code command: `Claude Code: Edit MCP Settings`

---

## Testing Your MCP Setup

After installing a server:

1. **Restart Claude Code** (VS Code: reload window)
2. **Test the tool**:
   ```
   Ask Claude: "List all MCP tools available"
   Expected: Should show your new server's tools

   Ask Claude: "Use the filesystem tool to show me a tree of the src/ directory"
   Expected: Calls the MCP tool and returns results
   ```
3. **Check logs** if it fails:
   - VS Code: Output panel → "Claude Code MCP"
   - Look for connection errors or missing env vars

---

## Next: Section 4 (Agent Patterns)
We'll define 5 lightweight agents that orchestrate these MCP tools into end-to-end workflows.
